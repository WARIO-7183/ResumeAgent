{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7ef49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayush\\OneDrive\\Desktop\\SPA EL\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, List, Any, Optional, TypedDict\n",
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pypdf import PdfReader\n",
    "from docx import Document\n",
    "import pytesseract\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field    \n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "594b039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from operator import or_\n",
    "\n",
    "def merge_dicts(a: dict, b: dict) -> dict:\n",
    "    \"\"\"Reducer to merge agent_outputs from parallel nodes.\"\"\"\n",
    "    return {**a, **b}\n",
    "\n",
    "class ResumeState(TypedDict, total=False):\n",
    "    resume_path: str\n",
    "    skills_required: List[str]\n",
    "    evaluate_experience: bool\n",
    "    evaluate_culture_fit: bool\n",
    "    job_description: str\n",
    "    resume_text: str\n",
    "    resume_embedding: List[float]\n",
    "    agent_outputs: Annotated[Dict[str, Dict[str, Any]], merge_dicts]\n",
    "    final_score: float\n",
    "    final_breakdown: Dict[str, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a194491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_resume_agent(state: ResumeState) -> dict:\n",
    "    resume_path = state.get(\"resume_path\")\n",
    "\n",
    "    if not resume_path or not os.path.exists(resume_path):\n",
    "        raise ValueError(\"Resume file path is invalid or file not found.\")\n",
    "\n",
    "    text = \"\"\n",
    "    # PDF Parsing\n",
    "    if resume_path.lower().endswith(\".pdf\"):\n",
    "        reader = PdfReader(resume_path)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "\n",
    "    # DOCX Parsing\n",
    "    elif resume_path.lower().endswith(\".docx\"):\n",
    "        doc = Document(resume_path)\n",
    "        for para in doc.paragraphs:\n",
    "            text += para.text + \"\\n\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only PDF/DOCX allowed.\")\n",
    "\n",
    "    # Clean text\n",
    "    clean_text = text.strip().replace(\"\\t\", \" \")\n",
    "\n",
    "    return {\"resume_text\": clean_text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6acce336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_25184\\2127729888.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce38e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_resume_agent(state: ResumeState) -> dict:\n",
    "    resume_text = state.get(\"resume_text\")\n",
    "    if not resume_text:\n",
    "        raise ValueError(\"Resume text not available. Parse step not completed.\")\n",
    "\n",
    "    # Generate embeddings from the extracted resume text\n",
    "    vector = embedding_model.embed_query(resume_text)\n",
    "    return {\"resume_embedding\": vector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701445ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    api_key=\"\",\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5481fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_match_agent(skill: str):\n",
    "    \"\"\"\n",
    "    Factory function that creates a dedicated skill evaluator agent\n",
    "    using ChatGroq via LangChain.\n",
    "    \"\"\"\n",
    "\n",
    "    def agent(state: ResumeState) -> dict:\n",
    "        resume_text = state.get(\"resume_text\")\n",
    "        if not resume_text:\n",
    "            raise ValueError(\"Resume text missing. Run parsing first.\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert resume evaluator.\n",
    "\n",
    "Here is the candidate's resume:\n",
    "---\n",
    "{resume_text}\n",
    "---\n",
    "\n",
    "Evaluate the candidate's proficiency in the skill: \"{skill}\".\n",
    "\n",
    "Return STRICTLY a JSON object with:\n",
    "- score: an integer from 0 to 10\n",
    "- explanation: a short 1-sentence justification\n",
    "\n",
    "Example format:\n",
    "{{\n",
    "  \"score\": 8,\n",
    "  \"explanation\": \"Strong evidence of experience with Python.\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        raw_output = response.content.strip()\n",
    "\n",
    "        import json\n",
    "        try:\n",
    "            result = json.loads(raw_output)\n",
    "        except Exception:\n",
    "            result = {\n",
    "                \"score\": 0,\n",
    "                \"explanation\": f\"Invalid JSON returned for skill '{skill}'. Raw output: {raw_output}\"\n",
    "            }\n",
    "\n",
    "        return {\"agent_outputs\": {f\"skill_{skill.lower().replace(' ', '_')}\": result}}\n",
    "\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9be01084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience_validation_agent(state: ResumeState) -> dict:\n",
    "    resume_text = state.get(\"resume_text\")\n",
    "    if not resume_text:\n",
    "        raise ValueError(\"Resume text missing. Run parsing first.\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a professional HR domain expert.\n",
    "\n",
    "Analyze the candidate's resume below:\n",
    "---\n",
    "{resume_text}\n",
    "---\n",
    "\n",
    "Evaluate the candidate's EXPERIENCE level based on:\n",
    "1. Total years of experience\n",
    "2. Relevance to industry and job roles\n",
    "3. Seniority & responsibilities handled\n",
    "4. Stability (frequency of job changes)\n",
    "5. Consistency and clarity of career progression\n",
    "\n",
    "Give a score strictly between 0 and 10 (integer only).\n",
    "\n",
    "Return STRICTLY a JSON object with:\n",
    "- score: integer 0–10\n",
    "- explanation: 1 brief sentence justification\n",
    "\n",
    "Example:\n",
    "{{\n",
    "  \"score\": 7,\n",
    "  \"explanation\": \"Candidate has around 3 years of relevant software development experience.\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    raw_output = response.content.strip()\n",
    "\n",
    "    import json\n",
    "    try:\n",
    "        result = json.loads(raw_output)\n",
    "    except:\n",
    "        result = {\n",
    "            \"score\": 0,\n",
    "            \"explanation\": f\"Invalid JSON for experience evaluation. Raw output: {raw_output}\"\n",
    "        }\n",
    "\n",
    "    return {\"agent_outputs\": {\"experience_validation\": result}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0527c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def culture_fit_agent(state: ResumeState) -> dict:\n",
    "    resume_text = state.get(\"resume_text\")\n",
    "    if not resume_text:\n",
    "        raise ValueError(\"Resume text missing. Run parsing first.\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an HR expert trained to evaluate cultural fit in organizations.\n",
    "\n",
    "Analyze this resume:\n",
    "---\n",
    "{resume_text}\n",
    "---\n",
    "\n",
    "Evaluate the candidate’s CULTURE FIT based on:\n",
    "1. Communication style and clarity\n",
    "2. Teamwork and collaboration signals\n",
    "3. Leadership traits (if any)\n",
    "4. Work ethic and adaptability\n",
    "5. Passion, initiative, ownership qualities\n",
    "6. Alignment with general corporate values\n",
    "\n",
    "Give a score strictly between 0 and 10 (integer only).\n",
    "\n",
    "Return STRICTLY a JSON object with:\n",
    "- score: integer from 0–10\n",
    "- explanation: one short sentence\n",
    "\n",
    "Example:\n",
    "{{\n",
    "  \"score\": 8,\n",
    "  \"explanation\": \"Shows strong teamwork, leadership, and communication alignment.\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    raw_output = response.content.strip()\n",
    "\n",
    "    import json\n",
    "    try:\n",
    "        result = json.loads(raw_output)\n",
    "    except:\n",
    "        result = {\n",
    "            \"score\": 0,\n",
    "            \"explanation\": f\"Invalid JSON for culture fit evaluation. Raw output: {raw_output}\"\n",
    "        }\n",
    "\n",
    "    return {\"agent_outputs\": {\"culture_fit\": result}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a9f3c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jd_match_agent(state: ResumeState) -> dict:\n",
    "    resume_text = state.get(\"resume_text\")\n",
    "    job_description = state.get(\"job_description\")\n",
    "    if not resume_text:\n",
    "        raise ValueError(\"Resume text missing. Run parsing first.\")\n",
    "    if not job_description:\n",
    "        raise ValueError(\"Job description missing. Provide JD before running this agent.\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a professional HR evaluator.\n",
    "\n",
    "Below is the JOB DESCRIPTION:\n",
    "---\n",
    "{job_description}\n",
    "---\n",
    "\n",
    "Below is the candidate's RESUME:\n",
    "---\n",
    "{resume_text}\n",
    "---\n",
    "\n",
    "Evaluate how well this candidate matches the JD based on:\n",
    "1. Required skills\n",
    "2. Relevant experience\n",
    "3. Responsibilities alignment\n",
    "4. Technical and soft skills match\n",
    "5. Domain-specific fit\n",
    "6. Overall suitability for the role\n",
    "\n",
    "Give a score STRICTLY between 0 and 10 (integer only).\n",
    "\n",
    "Return STRICTLY a JSON object:\n",
    "{{\n",
    "  \"score\": <0-10>,\n",
    "  \"explanation\": \"<1 sentence explanation>\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    raw_output = response.content.strip()\n",
    "\n",
    "    import json\n",
    "    try:\n",
    "        result = json.loads(raw_output)\n",
    "    except:\n",
    "        result = {\n",
    "            \"score\": 0,\n",
    "            \"explanation\": f\"Invalid JSON for JD match evaluation. Raw output: {raw_output}\"\n",
    "        }\n",
    "\n",
    "    return {\"agent_outputs\": {\"jd_match\": result}}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65b3abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator_agent(state: ResumeState) -> dict:\n",
    "    \"\"\"\n",
    "    Aggregates all scores from all agents (dynamic skill agents + fixed agents)\n",
    "    and produces a final score between 0 and 10.\n",
    "    \"\"\"\n",
    "\n",
    "    outputs = state.get(\"agent_outputs\", {})\n",
    "\n",
    "    if not outputs:\n",
    "        raise ValueError(\"No agent outputs found. Nothing to aggregate.\")\n",
    "\n",
    "    total_score = 0\n",
    "    count = 0\n",
    "    breakdown = {}\n",
    "\n",
    "    # Loop through all agents' results\n",
    "    for agent_name, result in outputs.items():\n",
    "        try:\n",
    "            score = int(result.get(\"score\", 0))\n",
    "        except:\n",
    "            score = 0  # if invalid score returned by LLM\n",
    "\n",
    "        # Store score in breakdown\n",
    "        breakdown[agent_name] = score\n",
    "\n",
    "        total_score += score\n",
    "        count += 1\n",
    "\n",
    "    # Compute final 0–10 average\n",
    "    if count > 0:\n",
    "        final_score = round(total_score / count, 2)\n",
    "    else:\n",
    "        final_score = 0\n",
    "\n",
    "    return {\"final_score\": final_score, \"final_breakdown\": breakdown}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f72b5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resume_graph(skills: list, evaluate_experience=True, evaluate_culture=True, evaluate_jd=True):\n",
    "    \"\"\"\n",
    "    Creates the full LangGraph pipeline dynamically based on HR input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the graph with ResumeState\n",
    "    graph = StateGraph(ResumeState)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Add Fixed Nodes\n",
    "    # -----------------------------\n",
    "    graph.add_node(\"parse_resume\", parse_resume_agent)\n",
    "    graph.add_node(\"embed_resume\", embed_resume_agent)\n",
    "\n",
    "    # Experience & Culture Fit agents (only added if required)\n",
    "    if evaluate_experience:\n",
    "        graph.add_node(\"experience_validation\", experience_validation_agent)\n",
    "\n",
    "    if evaluate_culture:\n",
    "        graph.add_node(\"culture_fit\", culture_fit_agent)\n",
    "\n",
    "    if evaluate_jd:\n",
    "        graph.add_node(\"jd_match\", jd_match_agent)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Add Dynamic Skill Nodes\n",
    "    # -----------------------------\n",
    "    skill_nodes = []\n",
    "\n",
    "    for skill in skills:\n",
    "        node_name = f\"skill_{skill.lower().replace(' ', '_')}\"\n",
    "        graph.add_node(node_name, skill_match_agent(skill))\n",
    "        skill_nodes.append(node_name)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Entry Point\n",
    "    # -----------------------------\n",
    "    graph.set_entry_point(\"parse_resume\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Sequential: parse → embed\n",
    "    # -----------------------------\n",
    "    graph.add_edge(\"parse_resume\", \"embed_resume\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Parallel Edges: embed → skill nodes\n",
    "    # -----------------------------\n",
    "    for node in skill_nodes:\n",
    "        graph.add_edge(\"embed_resume\", node)\n",
    "\n",
    "    # Parallel Edges: embed → fixed nodes\n",
    "    if evaluate_experience:\n",
    "        graph.add_edge(\"embed_resume\", \"experience_validation\")\n",
    "\n",
    "    if evaluate_culture:\n",
    "        graph.add_edge(\"embed_resume\", \"culture_fit\")\n",
    "\n",
    "    if evaluate_jd:\n",
    "        graph.add_edge(\"embed_resume\", \"jd_match\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Aggregator Node\n",
    "    # -----------------------------\n",
    "    graph.add_node(\"aggregate\", aggregator_agent)\n",
    "\n",
    "    # All nodes converge into the aggregator\n",
    "    fan_in_nodes = skill_nodes.copy()\n",
    "\n",
    "    if evaluate_experience:\n",
    "        fan_in_nodes.append(\"experience_validation\")\n",
    "\n",
    "    if evaluate_culture:\n",
    "        fan_in_nodes.append(\"culture_fit\")\n",
    "\n",
    "    if evaluate_jd:\n",
    "        fan_in_nodes.append(\"jd_match\")\n",
    "\n",
    "    # Connect all evaluation nodes → aggregate\n",
    "    for node in fan_in_nodes:\n",
    "        graph.add_edge(node, \"aggregate\")\n",
    "\n",
    "    # End of graph\n",
    "    graph.add_edge(\"aggregate\", END)\n",
    "\n",
    "    # Finalize\n",
    "    return graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dff4222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL SCORE: 6.83\n",
      "BREAKDOWN: {'culture_fit': 9, 'experience_validation': 8, 'jd_match': 0, 'skill_communication': 6, 'skill_machine_learning': 9, 'skill_python': 9}\n"
     ]
    }
   ],
   "source": [
    "graph = create_resume_graph(\n",
    "    skills=[\"python\", \"machine learning\", \"communication\"],\n",
    "    evaluate_experience=True,\n",
    "    evaluate_culture=True,\n",
    "    evaluate_jd=True\n",
    ")\n",
    "\n",
    "initial_state = {\n",
    "    \"resume_path\": \"Ayush_Chouhan_Software_Dev_NoLinks_Clean.pdf\",\n",
    "    \"job_description\": \"Looking for a backend engineer with ML + Python experience.\",\n",
    "    \"skills_required\": [\"python\", \"machine learning\", \"communication\"],\n",
    "    \"agent_outputs\": {}\n",
    "}\n",
    "\n",
    "result = graph.invoke(initial_state)\n",
    "\n",
    "print(\"FINAL SCORE:\", result[\"final_score\"])\n",
    "print(\"BREAKDOWN:\", result[\"final_breakdown\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
